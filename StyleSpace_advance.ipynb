{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleSpace_advance.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimalesh/L2i/blob/main/StyleSpace_advance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tl2tIrDQohU"
      },
      "source": [
        "# Get localized channels and attribute specific channels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()  # Force TF1-like behavior"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb0o4FuZClAa",
        "outputId": "7e51eda2-b30c-48f6-c51b-000993df9523"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VERMQoCcnF5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb713d8-8ee2-47dc-edfe-dffd88c7664e"
      },
      "source": [
        "#@title Setup (may take a few minutes)\n",
        "# %tensorflow_version 1.x\n",
        "!git clone https://github.com/betterze/StyleSpace\n",
        "%cd /content/StyleSpace"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StyleSpace'...\n",
            "remote: Enumerating objects: 346, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 346 (delta 62), reused 57 (delta 57), pack-reused 263 (from 1)\u001b[K\n",
            "Receiving objects: 100% (346/346), 155.75 MiB | 19.68 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Updating files: 100% (63/63), done.\n",
            "/content/StyleSpace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for tf.Session\n",
        "!grep -rnw '.' -e 'tf.Session'\n",
        "\n",
        "# Look for tf.placeholder\n",
        "!grep -rnw '.' -e 'tf.placeholder'\n",
        "\n",
        "# Look for tf.global_variables_initializer\n",
        "!grep -rnw '.' -e 'tf.global_variables_initializer'\n",
        "\n",
        "# Look for tf.contrib (deprecated)\n",
        "!grep -rnw '.' -e 'tf.contrib'\n",
        "\n",
        "# Look for tf.layers (replace with tf.keras.layers)\n",
        "!grep -rnw '.' -e 'tf.layers'\n",
        "\n",
        "# Optional: look for any use of TensorFlow\n",
        "!grep -rnw '.' -e 'import tensorflow'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6gPmWJ3cvST",
        "outputId": "837f1cf5-8aa8-4e46-f210-979c210431d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grep: ./dnnlib/tflib/__pycache__/tfutil.cpython-37.pyc: binary file matches\n",
            "./dnnlib/tflib/tfutil.py:151:def create_session(config_dict: dict = None, force_as_default: bool = False) -> tf.Session:\n",
            "./dnnlib/tflib/tfutil.py:152:    \"\"\"Create tf.Session based on config dict.\"\"\"\n",
            "./dnnlib/tflib/tfutil.py:165:    session = tf.Session(config=config_proto)\n",
            "./GetCode.py:48:    with tf.Session() as sess:\n",
            "./GetCode.py:144:    with tf.Session() as sess:\n",
            "./dnnlib/tflib/autosummary.py:112:                    update_value = tf.placeholder(_dtype)\n",
            "./dnnlib/tflib/network.py:148:                    self._input_templates.append(tf.placeholder(tf.float32, name=param.name))\n",
            "./dnnlib/tflib/network.py:589:                    in_expr = [tf.placeholder(tf.float32, name=name) for name in self.input_names]\n",
            "./dnnlib/tflib/tfutil.py:222:                    setter = tf.assign(var, tf.placeholder(var.dtype, var.shape, \"new_value\"), name=\"setter\")  # create new setter\n",
            "./invert_mask.py:220:    model_input=tf.placeholder(dtype='float32',shape=(1,layer_num,512),name='model_input')\n",
            "./GetCode.py:145:        init = tf.global_variables_initializer()\n",
            "./manipulate.py:113:        init = tf.global_variables_initializer()\n",
            "./dnnlib/tflib/optimizer.py:140:                    deps.append(autosummary.autosummary(self.id + \"/mem_usage_gb\", tf.contrib.memory_stats.BytesInUse() / 2**30))\n",
            "./dnnlib/tflib/tfutil.py:19:tf.contrib = tensorflow.contrib\n",
            "./dnnlib/tflib/autosummary.py:28:import tensorflow as tf\n",
            "./dnnlib/tflib/ops/upfirdn_2d.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/ops/fused_bias_act.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/optimizer.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/custom_ops.py:19:import tensorflow as tf\n",
            "./dnnlib/tflib/network.py:18:import tensorflow as tf\n",
            "./dnnlib/tflib/tfutil.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/tfutil.py:18:import tensorflow.contrib   # requires TensorFlow 1.x!\n",
            "./GetCode.py:10:import tensorflow as tf \n",
            "./manipulate.py:7:import tensorflow as tf\n",
            "./invert_mask.py:15:import tensorflow as tf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_slim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdoHo3NWC3Xk",
        "outputId": "0fb458de-51ab-4e3a-91ba-ef60700bd488"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name='ffhq' #only support ffhq\n",
        "# input prepare data\n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 'w'"
      ],
      "metadata": {
        "id": "ukLDj1iRK-o1",
        "outputId": "0aaedb97-f9ce-446e-a403-fcc7c376585a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-11 11:47:31.690103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746964051.713277    2322 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746964051.720081    2322 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 9, in <module>\n",
            "    from dnnlib import tflib  \n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/__init__.py\", line 11, in <module>\n",
            "    from . import optimizer\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/optimizer.py\", line 326, in <module>\n",
            "    class SimpleAdam:\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/optimizer.py\", line 340, in SimpleAdam\n",
            "    def compute_gradients(self, loss, var_list, gate_gradients=tf.train.Optimizer.GATE_NONE):\n",
            "                                                               ^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: module 'tensorflow._api.v2.train' has no attribute 'Optimizer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !python GetCode.py --dataset_name $dataset_name --code_type 's'\n",
        "# !python GetCode.py --dataset_name $dataset_name --code_type 's_mean_std'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from MAdvance import MAdvance\n",
        "M=MAdvance(dataset_name=dataset_name)\n",
        "\n",
        "with open(M.img_path+'grad_example', 'rb') as handle:\n",
        "        grads = pickle.load(handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        },
        "id": "EeSi-VZNcXHV",
        "outputId": "18d7101d-9404-4c10-816c-7561a9bf92bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-11 11:46:47.230975: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746964007.253445    2137 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746964007.260215    2137 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 9, in <module>\n",
            "    from dnnlib import tflib  \n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/__init__.py\", line 9, in <module>\n",
            "    from . import autosummary\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/autosummary.py\", line 32, in <module>\n",
            "    from . import tfutil\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/tfutil.py\", line 18, in <module>\n",
            "    import tensorflow.contrib   # requires TensorFlow 1.x!\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ModuleNotFoundError: No module named 'tensorflow.contrib'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow.contrib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-94c11933be43>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMAdvance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAdvance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAdvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/MAdvance.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmanipulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mManipulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/manipulate.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdnnlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtflib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHtmlPageVisualizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/dnnlib/tflib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# license agreement from NVIDIA CORPORATION is strictly prohibited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautosummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/dnnlib/tflib/autosummary.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_scalar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtfutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtfutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfExpression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtfutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfExpressionEx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/dnnlib/tflib/tfutil.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m   \u001b[0;31m# requires TensorFlow 1.x!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1aDyWYtRnk-"
      },
      "source": [
        "# gradient map of a single channel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t1KqqnBEJXe",
        "cellView": "form"
      },
      "source": [
        "img_index='0' #@param [0,1,2,3,4,5,6,7,8,9]\n",
        "img_index=int(img_index)\n",
        "LayerIndex_ChannelIndex='9_409' #@param ['12_266','11_286','3_169','6_83','6_501','15_45','9_409','9_376','8_28']\n",
        "manipulation_strength='5' #@param [3, 5, 10, 15]\n",
        "alpha=int(manipulation_strength)\n",
        "\n",
        "tmp=LayerIndex_ChannelIndex.split('_')\n",
        "lindex,cindex=int(tmp[0]),int(tmp[1])\n",
        "grad=grads[lindex][img_index,cindex]\n",
        "tmp=np.zeros([32,32,3]).astype('uint8')\n",
        "tmp[:,:,1]=grad\n",
        "grad1=Image.fromarray(tmp).resize((256,256))\n",
        "\n",
        "M.alpha=[0]\n",
        "M.img_index=img_index\n",
        "M.num_images=1\n",
        "M.manipulate_layers=[lindex]\n",
        "codes,out=M.EditOneC(cindex)\n",
        "original=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "original = original.convert(\"RGBA\")\n",
        "grad1 = grad1.convert(\"RGBA\")\n",
        "new_img = Image.blend(original, grad1, 0.5)\n",
        "\n",
        "M.alpha=[-alpha,alpha]\n",
        "M.manipulate_layers=[lindex]\n",
        "codes,out=M.EditOneC(cindex)\n",
        "positive=Image.fromarray(out[0,1]).resize((256,256))\n",
        "negative=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "plt.figure(figsize=(20,5), dpi= 100)\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(original)\n",
        "plt.title('original')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(new_img)\n",
        "plt.title('gradient')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(positive)\n",
        "plt.title('positive manipulation')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(negative)\n",
        "plt.title('negative manipulation')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYO8sWpRwgN"
      },
      "source": [
        "# show localized channels\n",
        "For each semantic area, we show the most localized channles in this area, measured by IoU between semantic map and gradient map. The layer index and channel index is on the y label of each row.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt8AG8Tk8HqM",
        "cellView": "form"
      },
      "source": [
        "area='hair' #@param ['eyebrow','eye','ear', 'nose', 'mouth', 'neck', 'clothes', 'hair']\n",
        "number_channel_to_view='10' #@param [ 10, 15, 20]\n",
        "num_view=int(number_channel_to_view)\n",
        "\n",
        "img_index='0' #@param [0,1,2,3,4,5,6,7,8,9]\n",
        "img_index=int(img_index)\n",
        "manipulation_strength='10' #@param [ 5, 10, 15,20]\n",
        "alpha=int(manipulation_strength)\n",
        "\n",
        "tmp=list(M.label.values).index(area)\n",
        "target_index=(tmp,)\n",
        "lp_candidate,_=M.GetRank(target_index)\n",
        "print('number of localized channels in this area',lp_candidate.shape[0])\n",
        "\n",
        "M.alpha=[0]\n",
        "M.img_index=img_index\n",
        "M.num_images=1\n",
        "M.manipulate_layers=[0]\n",
        "codes,out=M.EditOneC(0)\n",
        "original=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "M.alpha=[-alpha,alpha]\n",
        "imgs=[]\n",
        "\n",
        "for i in range(num_view):\n",
        "  lindex,cindex,_=lp_candidate[i]\n",
        "  lindex,cindex=int(lindex),int(cindex)\n",
        "  M.manipulate_layers=[lindex]\n",
        "  codes,out=M.EditOneC(cindex)\n",
        "  imgs.append(out)\n",
        "imgs=np.concatenate(imgs)\n",
        "\n",
        "plt.figure(figsize=(15,5*num_view), dpi= 100)\n",
        "tmp_index=1\n",
        "for i in range(num_view):\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  lindex,cindex,rate=lp_candidate[i]\n",
        "  #rate=round(rate,2)\n",
        "  tmp=(int(lindex),int(cindex))\n",
        "  plt.ylabel(str(tmp))\n",
        "  img=Image.fromarray(imgs[i,0]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('negative')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  plt.imshow(original)\n",
        "  plt.title('original')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  img=Image.fromarray(imgs[i,1]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('positive')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiyE53m8ZIv2"
      },
      "source": [
        "# attribute specific channels\n",
        "Given a set of examplar images that contain a certain attribute (for example, smiling), we design a simple algorithm based on signal2noise ratio to detect the channels that control this attribute. Large S2N means this channel has large potential to control target attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLFpuXon-9y7",
        "cellView": "form"
      },
      "source": [
        "\n",
        "attribute='goatee' #@param['male', 'smiling', 'wavy-hair','bald', 'bangs', 'black-hair', 'blond-hair', 'eyeglasses', 'goatee', 'gray-hair', 'receding-hairline', 'sideburns',  'wearing-earrings', 'wearing-lipstick', 'wearing-necktie']\n",
        "\n",
        "M.bname=attribute\n",
        "lp_candidate,lp_sort= M.AllCheck()\n",
        "plt.figure(figsize=(10,6), dpi= 100)\n",
        "plt.title(M.bname)\n",
        "plt.plot(lp_sort[:10],'*')\n",
        "plt.ylabel('signal2noise')\n",
        "plt.xlabel('(layer_index, channel_index)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4_3FxSBRTVP",
        "cellView": "form"
      },
      "source": [
        "number_channel_to_view='3' #@param [3, 5, 10]\n",
        "num_view=int(number_channel_to_view)\n",
        "\n",
        "img_index='0' #@param [0,1,2,3,4,5,6,7,8,9]\n",
        "img_index=int(img_index)\n",
        "manipulation_strength='5' #@param [ 5, 10, 15,20]\n",
        "alpha=int(manipulation_strength)\n",
        "\n",
        "\n",
        "\n",
        "M.alpha=[0]\n",
        "M.img_index=img_index\n",
        "M.num_images=1\n",
        "M.manipulate_layers=[0]\n",
        "codes,out=M.EditOneC(0)\n",
        "original=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "M.alpha=[-alpha,alpha]\n",
        "imgs=[]\n",
        "\n",
        "for i in range(num_view):\n",
        "  lindex,cindex,_=lp_candidate[i]\n",
        "  lindex,cindex=int(lindex),int(cindex)\n",
        "  M.manipulate_layers=[lindex]\n",
        "  codes,out=M.EditOneC(cindex)\n",
        "  imgs.append(out)\n",
        "imgs=np.concatenate(imgs)\n",
        "\n",
        "plt.figure(figsize=(15,5*num_view), dpi= 100)\n",
        "tmp_index=1\n",
        "for i in range(num_view):\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  lindex,cindex,rate=lp_candidate[i]\n",
        "  #rate=round(rate,2)\n",
        "  tmp=(int(lindex),int(cindex))\n",
        "  plt.ylabel(str(tmp))\n",
        "  img=Image.fromarray(imgs[i,0]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('negative')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  plt.imshow(original)\n",
        "  plt.title('original')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  img=Image.fromarray(imgs[i,1]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('positive')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqkXJT0QFbqx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}