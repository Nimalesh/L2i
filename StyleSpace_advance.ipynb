{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleSpace_advance.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimalesh/L2i/blob/main/StyleSpace_advance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Tl2tIrDQohU"
      },
      "source": [
        "# Get localized channels and attribute specific channels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()  # Force TF1-like behavior"
      ],
      "metadata": {
        "id": "Xb0o4FuZClAa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VERMQoCcnF5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3323610c-571b-4a27-8690-adc54adab380"
      },
      "source": [
        "#@title Setup (may take a few minutes)\n",
        "# %tensorflow_version 1.x\n",
        "!git clone https://github.com/betterze/StyleSpace\n",
        "%cd /content/StyleSpace"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'StyleSpace'...\n",
            "remote: Enumerating objects: 346, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 346 (delta 62), reused 57 (delta 57), pack-reused 263 (from 1)\u001b[K\n",
            "Receiving objects: 100% (346/346), 155.75 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Updating files: 100% (63/63), done.\n",
            "/content/StyleSpace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look for tf.Session\n",
        "!grep -rnw '.' -e 'tf.Session'\n",
        "\n",
        "# Look for tf.placeholder\n",
        "!grep -rnw '.' -e 'tf.placeholder'\n",
        "\n",
        "# Look for tf.global_variables_initializer\n",
        "!grep -rnw '.' -e 'tf.global_variables_initializer'\n",
        "\n",
        "# Look for tf.contrib (deprecated)\n",
        "!grep -rnw '.' -e 'tf.contrib'\n",
        "\n",
        "# Look for tf.layers (replace with tf.keras.layers)\n",
        "!grep -rnw '.' -e 'tf.layers'\n",
        "\n",
        "# Optional: look for any use of TensorFlow\n",
        "!grep -rnw '.' -e 'import tensorflow'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6gPmWJ3cvST",
        "outputId": "837f1cf5-8aa8-4e46-f210-979c210431d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grep: ./dnnlib/tflib/__pycache__/tfutil.cpython-37.pyc: binary file matches\n",
            "./dnnlib/tflib/tfutil.py:151:def create_session(config_dict: dict = None, force_as_default: bool = False) -> tf.Session:\n",
            "./dnnlib/tflib/tfutil.py:152:    \"\"\"Create tf.Session based on config dict.\"\"\"\n",
            "./dnnlib/tflib/tfutil.py:165:    session = tf.Session(config=config_proto)\n",
            "./GetCode.py:48:    with tf.Session() as sess:\n",
            "./GetCode.py:144:    with tf.Session() as sess:\n",
            "./dnnlib/tflib/autosummary.py:112:                    update_value = tf.placeholder(_dtype)\n",
            "./dnnlib/tflib/network.py:148:                    self._input_templates.append(tf.placeholder(tf.float32, name=param.name))\n",
            "./dnnlib/tflib/network.py:589:                    in_expr = [tf.placeholder(tf.float32, name=name) for name in self.input_names]\n",
            "./dnnlib/tflib/tfutil.py:222:                    setter = tf.assign(var, tf.placeholder(var.dtype, var.shape, \"new_value\"), name=\"setter\")  # create new setter\n",
            "./invert_mask.py:220:    model_input=tf.placeholder(dtype='float32',shape=(1,layer_num,512),name='model_input')\n",
            "./GetCode.py:145:        init = tf.global_variables_initializer()\n",
            "./manipulate.py:113:        init = tf.global_variables_initializer()\n",
            "./dnnlib/tflib/optimizer.py:140:                    deps.append(autosummary.autosummary(self.id + \"/mem_usage_gb\", tf.contrib.memory_stats.BytesInUse() / 2**30))\n",
            "./dnnlib/tflib/tfutil.py:19:tf.contrib = tensorflow.contrib\n",
            "./dnnlib/tflib/autosummary.py:28:import tensorflow as tf\n",
            "./dnnlib/tflib/ops/upfirdn_2d.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/ops/fused_bias_act.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/optimizer.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/custom_ops.py:19:import tensorflow as tf\n",
            "./dnnlib/tflib/network.py:18:import tensorflow as tf\n",
            "./dnnlib/tflib/tfutil.py:13:import tensorflow as tf\n",
            "./dnnlib/tflib/tfutil.py:18:import tensorflow.contrib   # requires TensorFlow 1.x!\n",
            "./GetCode.py:10:import tensorflow as tf \n",
            "./manipulate.py:7:import tensorflow as tf\n",
            "./invert_mask.py:15:import tensorflow as tf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_slim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdoHo3NWC3Xk",
        "outputId": "0fb458de-51ab-4e3a-91ba-ef60700bd488"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name='ffhq' #only support ffhq\n",
        "# input prepare data\n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 'w'\n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 's'\n",
        "!python GetCode.py --dataset_name $dataset_name --code_type 's_mean_std'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from MAdvance import MAdvance\n",
        "M=MAdvance(dataset_name=dataset_name)\n",
        "\n",
        "with open(M.img_path+'grad_example', 'rb') as handle:\n",
        "        grads = pickle.load(handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EeSi-VZNcXHV",
        "outputId": "7063cf5e-002c-4d3b-a681-1d005cc0d9af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-11 11:29:57.953857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746962997.975761    6505 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746962997.982653    6505 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "output_path: ./npy/ffhq\n",
            "2025-05-11 11:30:01.408652: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 237, in <module>\n",
            "    dlatents=GetCode(Gs,random_state,num_img,num_once,truncation)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 86, in GetCode\n",
            "    dlatent_avg=Gs.get_var('dlatent_avg')\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 399, in get_var\n",
            "    return self.find_var(var_or_local_name).eval()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 394, in find_var\n",
            "    return self._get_vars()[var_or_local_name] if isinstance(var_or_local_name, str) else var_or_local_name\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 297, in _get_vars\n",
            "    self._vars = OrderedDict(self._get_own_vars())\n",
            "                             ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 286, in _get_own_vars\n",
            "    self._init_graph()\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 151, in _init_graph\n",
            "    out_expr = self._build_func(*self._input_templates, **build_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 187, in G_main\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 232, in input_shape\n",
            "    return self.input_shapes[0]\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 219, in input_shapes\n",
            "    self._input_shapes = [t.shape.as_list() for t in self.input_templates]\n",
            "                                                     ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 267, in input_templates\n",
            "    self._init_graph()\n",
            "  File \"/content/StyleSpace/dnnlib/tflib/network.py\", line 151, in _init_graph\n",
            "    out_expr = self._build_func(*self._input_templates, **build_kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 451, in G_synthesis_stylegan2\n",
            "AttributeError: module 'tensorflow' has no attribute 'get_variable'\n",
            "2025-05-11 11:30:03.241030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746963003.261636    6541 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746963003.267756    6541 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "output_path: ./npy/ffhq\n",
            "Generate S\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 245, in <module>\n",
            "    save_tmp=GetS(output_path,num_img=2_000)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 142, in GetS\n",
            "    dlatents=np.load(tmp)[:num_img]\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\", line 455, in load\n",
            "    fid = stack.enter_context(open(os.fspath(file), \"rb\"))\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './npy/ffhq/W.npy'\n",
            "2025-05-11 11:30:08.764213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746963008.783493    6577 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746963008.789573    6577 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "output_path: ./npy/ffhq\n",
            "Generate S\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 251, in <module>\n",
            "    save_tmp=GetS(output_path,num_img=num_img)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/StyleSpace/GetCode.py\", line 142, in GetS\n",
            "    dlatents=np.load(tmp)[:num_img]\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\", line 455, in load\n",
            "    fid = stack.enter_context(open(os.fspath(file), \"rb\"))\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './npy/ffhq/W.npy'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './npy/ffhq/S'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-99522c9fbb0b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMAdvance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAdvance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAdvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'grad_example'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/MAdvance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_bank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;31m#example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/manipulate.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_name)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanipulate_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;31m#which layer to manipulate, list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlatents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmindexs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpindexs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLoadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/StyleSpace/manipulate.py\u001b[0m in \u001b[0;36mLoadData\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mLoadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m#Pickling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0ms_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mdlatents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './npy/ffhq/S'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1aDyWYtRnk-"
      },
      "source": [
        "# gradient map of a single channel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t1KqqnBEJXe",
        "cellView": "form"
      },
      "source": [
        "img_index='0' #@param [0,1,2,3,4,5,6,7,8,9]\n",
        "img_index=int(img_index)\n",
        "LayerIndex_ChannelIndex='9_409' #@param ['12_266','11_286','3_169','6_83','6_501','15_45','9_409','9_376','8_28']\n",
        "manipulation_strength='5' #@param [3, 5, 10, 15]\n",
        "alpha=int(manipulation_strength)\n",
        "\n",
        "tmp=LayerIndex_ChannelIndex.split('_')\n",
        "lindex,cindex=int(tmp[0]),int(tmp[1])\n",
        "grad=grads[lindex][img_index,cindex]\n",
        "tmp=np.zeros([32,32,3]).astype('uint8')\n",
        "tmp[:,:,1]=grad\n",
        "grad1=Image.fromarray(tmp).resize((256,256))\n",
        "\n",
        "M.alpha=[0]\n",
        "M.img_index=img_index\n",
        "M.num_images=1\n",
        "M.manipulate_layers=[lindex]\n",
        "codes,out=M.EditOneC(cindex)\n",
        "original=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "original = original.convert(\"RGBA\")\n",
        "grad1 = grad1.convert(\"RGBA\")\n",
        "new_img = Image.blend(original, grad1, 0.5)\n",
        "\n",
        "M.alpha=[-alpha,alpha]\n",
        "M.manipulate_layers=[lindex]\n",
        "codes,out=M.EditOneC(cindex)\n",
        "positive=Image.fromarray(out[0,1]).resize((256,256))\n",
        "negative=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "plt.figure(figsize=(20,5), dpi= 100)\n",
        "plt.subplot(1,4,1)\n",
        "plt.imshow(original)\n",
        "plt.title('original')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,2)\n",
        "plt.imshow(new_img)\n",
        "plt.title('gradient')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,3)\n",
        "plt.imshow(positive)\n",
        "plt.title('positive manipulation')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,4,4)\n",
        "plt.imshow(negative)\n",
        "plt.title('negative manipulation')\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCYO8sWpRwgN"
      },
      "source": [
        "# show localized channels\n",
        "For each semantic area, we show the most localized channles in this area, measured by IoU between semantic map and gradient map. The layer index and channel index is on the y label of each row.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt8AG8Tk8HqM",
        "cellView": "form"
      },
      "source": [
        "area='hair' #@param ['eyebrow','eye','ear', 'nose', 'mouth', 'neck', 'clothes', 'hair']\n",
        "number_channel_to_view='10' #@param [ 10, 15, 20]\n",
        "num_view=int(number_channel_to_view)\n",
        "\n",
        "img_index='0' #@param [0,1,2,3,4,5,6,7,8,9]\n",
        "img_index=int(img_index)\n",
        "manipulation_strength='10' #@param [ 5, 10, 15,20]\n",
        "alpha=int(manipulation_strength)\n",
        "\n",
        "tmp=list(M.label.values).index(area)\n",
        "target_index=(tmp,)\n",
        "lp_candidate,_=M.GetRank(target_index)\n",
        "print('number of localized channels in this area',lp_candidate.shape[0])\n",
        "\n",
        "M.alpha=[0]\n",
        "M.img_index=img_index\n",
        "M.num_images=1\n",
        "M.manipulate_layers=[0]\n",
        "codes,out=M.EditOneC(0)\n",
        "original=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "M.alpha=[-alpha,alpha]\n",
        "imgs=[]\n",
        "\n",
        "for i in range(num_view):\n",
        "  lindex,cindex,_=lp_candidate[i]\n",
        "  lindex,cindex=int(lindex),int(cindex)\n",
        "  M.manipulate_layers=[lindex]\n",
        "  codes,out=M.EditOneC(cindex)\n",
        "  imgs.append(out)\n",
        "imgs=np.concatenate(imgs)\n",
        "\n",
        "plt.figure(figsize=(15,5*num_view), dpi= 100)\n",
        "tmp_index=1\n",
        "for i in range(num_view):\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  lindex,cindex,rate=lp_candidate[i]\n",
        "  #rate=round(rate,2)\n",
        "  tmp=(int(lindex),int(cindex))\n",
        "  plt.ylabel(str(tmp))\n",
        "  img=Image.fromarray(imgs[i,0]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('negative')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  plt.imshow(original)\n",
        "  plt.title('original')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  img=Image.fromarray(imgs[i,1]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('positive')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiyE53m8ZIv2"
      },
      "source": [
        "# attribute specific channels\n",
        "Given a set of examplar images that contain a certain attribute (for example, smiling), we design a simple algorithm based on signal2noise ratio to detect the channels that control this attribute. Large S2N means this channel has large potential to control target attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLFpuXon-9y7",
        "cellView": "form"
      },
      "source": [
        "\n",
        "attribute='goatee' #@param['male', 'smiling', 'wavy-hair','bald', 'bangs', 'black-hair', 'blond-hair', 'eyeglasses', 'goatee', 'gray-hair', 'receding-hairline', 'sideburns',  'wearing-earrings', 'wearing-lipstick', 'wearing-necktie']\n",
        "\n",
        "M.bname=attribute\n",
        "lp_candidate,lp_sort= M.AllCheck()\n",
        "plt.figure(figsize=(10,6), dpi= 100)\n",
        "plt.title(M.bname)\n",
        "plt.plot(lp_sort[:10],'*')\n",
        "plt.ylabel('signal2noise')\n",
        "plt.xlabel('(layer_index, channel_index)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4_3FxSBRTVP",
        "cellView": "form"
      },
      "source": [
        "number_channel_to_view='3' #@param [3, 5, 10]\n",
        "num_view=int(number_channel_to_view)\n",
        "\n",
        "img_index='0' #@param [0,1,2,3,4,5,6,7,8,9]\n",
        "img_index=int(img_index)\n",
        "manipulation_strength='5' #@param [ 5, 10, 15,20]\n",
        "alpha=int(manipulation_strength)\n",
        "\n",
        "\n",
        "\n",
        "M.alpha=[0]\n",
        "M.img_index=img_index\n",
        "M.num_images=1\n",
        "M.manipulate_layers=[0]\n",
        "codes,out=M.EditOneC(0)\n",
        "original=Image.fromarray(out[0,0]).resize((256,256))\n",
        "\n",
        "M.alpha=[-alpha,alpha]\n",
        "imgs=[]\n",
        "\n",
        "for i in range(num_view):\n",
        "  lindex,cindex,_=lp_candidate[i]\n",
        "  lindex,cindex=int(lindex),int(cindex)\n",
        "  M.manipulate_layers=[lindex]\n",
        "  codes,out=M.EditOneC(cindex)\n",
        "  imgs.append(out)\n",
        "imgs=np.concatenate(imgs)\n",
        "\n",
        "plt.figure(figsize=(15,5*num_view), dpi= 100)\n",
        "tmp_index=1\n",
        "for i in range(num_view):\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  lindex,cindex,rate=lp_candidate[i]\n",
        "  #rate=round(rate,2)\n",
        "  tmp=(int(lindex),int(cindex))\n",
        "  plt.ylabel(str(tmp))\n",
        "  img=Image.fromarray(imgs[i,0]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('negative')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  plt.imshow(original)\n",
        "  plt.title('original')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "  plt.subplot(num_view,3,tmp_index)\n",
        "  img=Image.fromarray(imgs[i,1]).resize((256,256))\n",
        "  plt.imshow(img)\n",
        "  plt.title('positive')\n",
        "  plt.gca().axes.yaxis.set_ticklabels([])\n",
        "  plt.gca().axes.xaxis.set_ticklabels([])\n",
        "  tmp_index+=1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqkXJT0QFbqx"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}